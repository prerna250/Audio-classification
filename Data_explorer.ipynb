{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2qob46UyBdD"
      },
      "outputs": [],
      "source": [
        "# % pylab inline\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import glob \n",
        "import matplotlib.pyplot as plt\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhCG2ZoLyBdJ"
      },
      "source": [
        "This function is used to plot out a waveplot of audio file. It expects the filename (along with it's path as its argument)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQ5oLJhLyBdN"
      },
      "outputs": [],
      "source": [
        "def showSpectrogram(filename):\n",
        "    data, sampling_rate = librosa.load(filename)\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    librosa.display.waveplot(data, sr=sampling_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFK0739cyBdO"
      },
      "outputs": [],
      "source": [
        "showSpectrogram('./Audio_Data/Chinese/clips/common_voice_zh-CN_18659733.mp3')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ud1rdnhOyBdT"
      },
      "source": [
        "Below are 2 function, create_spectrogram & create_mfcc_spectrogram.\n",
        "\n",
        "These function create an image from audio file (argument filename specifies this, which should be the path of the audio file along with it's name) and stores it with a name and path defined by the argument newFilePath which should be the path of the image along with it's name.\n",
        "\n",
        "We ended up using only simple create_spectrogram function which creates Mel Spectrogram images. We tried the model using MFCC feature images of the sound through the create_mfcc_spectrogram function but the results weren't as good. The code in the main CNN_model notebook uses the files from create_spectrogram function as used below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnfparxGyBdU"
      },
      "outputs": [],
      "source": [
        "def create_spectrogram(filename,newFilePath):\n",
        "    plt.interactive(False)\n",
        "    clip, sample_rate = librosa.load(filename, sr=None)\n",
        "    fig = plt.figure(figsize=[0.72,0.72])\n",
        "    ax = fig.add_subplot(111)\n",
        "    ax.axes.get_xaxis().set_visible(False)\n",
        "    ax.axes.get_yaxis().set_visible(False)\n",
        "    ax.set_frame_on(False)\n",
        "    S = librosa.feature.melspectrogram(y=clip, sr=sample_rate)\n",
        "    librosa.display.specshow(librosa.power_to_db(S, ref=np.max))\n",
        "    plt.savefig(newFilePath, dpi=400, bbox_inches='tight',pad_inches=0)\n",
        "    plt.close()    \n",
        "    fig.clf()\n",
        "    plt.close(fig)\n",
        "    plt.close('all')\n",
        "    \n",
        "def create_mfcc_spectrogram(filename,newFilePath):\n",
        "    plt.interactive(False)\n",
        "    clip, sample_rate = librosa.load(filename, sr=None)\n",
        "    fig = plt.figure(figsize=[0.72,0.72])\n",
        "    ax = fig.add_subplot(111)\n",
        "    ax.axes.get_xaxis().set_visible(False)\n",
        "    ax.axes.get_yaxis().set_visible(False)\n",
        "    ax.set_frame_on(False)\n",
        "    S = librosa.feature.mfcc(y=clip, sr=sample_rate, n_mfcc=40)\n",
        "    librosa.display.specshow(librosa.power_to_db(S, ref=np.max))\n",
        "    plt.savefig(newFilePath, dpi=400, bbox_inches='tight',pad_inches=0) #saves at a file path\n",
        "    plt.close()    \n",
        "    fig.clf()\n",
        "    plt.close(fig)\n",
        "    plt.close('all')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOY3rFkqyBdW"
      },
      "source": [
        "Just a test for these function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "99Bf3ffgyBdX"
      },
      "outputs": [],
      "source": [
        "create_mfcc_spectrogram('./Audio_Data/Chinese/clips/common_voice_zh-CN_18659734.mp3', './test1.jpg')\n",
        "create_spectrogram('./Audio_Data/Chinese/clips/common_voice_zh-CN_18659734.mp3', './test2.jpg') #to add data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLXxNofQyBdY"
      },
      "source": [
        "These are the 5 languages (the uncommented one) we ended up using for finally training the model. To increase the number of languages whose data is transformed into images, add other languages to this array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5L9Uq2wyBda"
      },
      "outputs": [],
      "source": [
        "# Languages = [\n",
        "#     'French',\n",
        "#     'German',\n",
        "#     'Dutch',\n",
        "#     'Russian',\n",
        "#     'Spanish',\n",
        "#     'Italian',\n",
        "#     'Turkish',\n",
        "#     'Persian',\n",
        "#     'Swedish',\n",
        "#     'Mongolian',\n",
        "#     'Chinese'\n",
        "#     ] test cases\n",
        "\n",
        "Languages = ['Turkish', 'Dutch', 'Swedish', 'Mongolian', 'Persian']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRIaTn68yBdb"
      },
      "source": [
        "This block can be used to get Mel Spectrogram feature images for the samples sepcified in the range (currently 3500, 5000) of each language specified above in the Languages array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVcYvt0OyBdb"
      },
      "outputs": [],
      "source": [
        "for language in Languages:\n",
        "    Image_data_path = f'./Image_Data/{language}'\n",
        "    if not os.path.isdir(Image_data_path):\n",
        "        os.makedirs(Image_data_path)\n",
        "    \n",
        "    files = os.listdir(f'./Audio_Data/{language}/clips')\n",
        "    for i in range(3500,5000):\n",
        "        create_spectrogram(f'./Audio_Data/{language}/clips/{files[i]}', f'./Image_Data/{language}/{files[i][:-4]}.jpg') #spectogram save\n",
        "        \n",
        "    print(f'{language} done')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "EkYlGpbF4gey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBoPBFejyBdd"
      },
      "source": [
        "This block can be used to get the test Mel Spectrogram feature images using 375 images samples after the 1500 images of each language specified above in the Languages array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAGrVBpkyBdd"
      },
      "outputs": [],
      "source": [
        "for language in Languages:\n",
        "    Image_data_path = f'./Image_Data_Test/{language}'\n",
        "    if not os.path.isdir(Image_data_path):\n",
        "        os.makedirs(Image_data_path)\n",
        "    \n",
        "    files = os.listdir(f'./Audio_Data/{language}/clips')\n",
        "    for i in range(375):\n",
        "        create_spectrogram(f'./Audio_Data/{language}/clips/{files[1501 + i]}', f'./Image_Data_Test/{language}/{files[1501 + i][:-4]}.jpg')\n",
        "        \n",
        "    print(f'{language} done')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b576pjEWyBde"
      },
      "source": [
        "This block can be used to get MFCC feature images for the first 1500 samples of each language specified above in the Languages array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxmxgS3-yBdf"
      },
      "outputs": [],
      "source": [
        "for language in Languages:\n",
        "    Image_data_path = f'./Image_Data_MFCC/{language}'\n",
        "    if not os.path.isdir(Image_data_path):\n",
        "        os.makedirs(Image_data_path)\n",
        "    \n",
        "    files = os.listdir(f'./Audio_Data/{language}/clips')\n",
        "    for i in range(1500):\n",
        "        create_mfcc_spectrogram(f'./Audio_Data/{language}/clips/{files[i]}', f'./Image_Data_MFCC/{language}/{files[i][:-4]}.jpg')\n",
        "        \n",
        "    print(f'{language} done')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBcXdKfZyBdi"
      },
      "source": [
        "This block can be used to get the test MFCC feature images using 375 images samples after the 1500 images of each language specified above in the Languages array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6I-p4bjyBdi"
      },
      "outputs": [],
      "source": [
        "for language in Languages:\n",
        "    Image_data_path = f'./Image_Data_MFCC_Test/{language}'\n",
        "    if not os.path.isdir(Image_data_path):\n",
        "        os.makedirs(Image_data_path)\n",
        "    \n",
        "    files = os.listdir(f'./Audio_Data/{language}/clips')\n",
        "    for i in range(375):\n",
        "        create_spectrogram(f'./Audio_Data/{language}/clips/{files[1501 + i]}', f'./Image_Data_MFCC_Test/{language}/{files[1501 + i][:-4]}.jpg')\n",
        "        \n",
        "    print(f'{language} done')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFh9shlKyBdm"
      },
      "source": [
        "This was used to get the average length of audio files for each language. This was calculated using only the first 375 files as for bigger numbers it start to quite a bit of time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-tjHY9uyBdn"
      },
      "outputs": [],
      "source": [
        "for language in Languages:\n",
        "    files = os.listdir(f'./Audio_Data/{language}/clips')\n",
        "    totalLength = 0\n",
        "    \n",
        "    for i in range(375):\n",
        "        totalLength += librosa.get_duration(filename=f'./Audio_Data/{language}/clips/{files[i]}')\n",
        "            \n",
        "    print(f'{language} done with totalLength: {totalLength} & avgLength: {totalLength/375}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqfuEpNJyBdp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "environment": {
      "name": "tf2-gpu.2-1.m46",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m46"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}